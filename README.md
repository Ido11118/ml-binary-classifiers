# Binary Classification with Perceptron, Linear and Logistic Regression

This project explores three foundational machine learning algorithms applied to binary classification of handwritten digits. All algorithms are implemented manually using NumPy, without relying on high-level machine learning libraries like scikit-learn.

The notebook demonstrates the use of:

- **Perceptron** â€“ a linear classifier that updates weights based on misclassified samples
- **Linear Regression** â€“ adapted for classification to serve as a simple baseline
- **Logistic Regression** â€“ trained using gradient descent for probabilistic classification

---

## ğŸ“ File

- `basic-binary-classifiers.ipynb` â€“ the main notebook containing all algorithm implementations, training, and evaluation

---

## ğŸ§ª Dataset

- MNIST dataset (or a subset of it) is used to classify images of handwritten digits
- Binary task: classify a specific digit (e.g., `0`) versus all other digits

---

## ğŸš€ Features

- Manual implementation of all three models
- Training loop from scratch using NumPy
- Accuracy and loss tracking per iteration
- Visual comparison of performance

---

## ğŸ¯ Educational Purpose

This project was developed as an educational exercise to deepen understanding of linear classifiers and training algorithms. It provides hands-on experience with the inner workings of Perceptron and gradient-based optimization.

---

## ğŸ‘¤ Author
Ido  
GitHub: [@Ido11118](https://github.com/Ido11118)

